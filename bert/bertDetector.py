import torch
from transformers import BertTokenizer, BertForSequenceClassification
import nltk
import pandas as pd
nltk.download('punkt', quiet=True)
from nltk.tokenize import sent_tokenize

# Load trained model and tokenizer
model = BertForSequenceClassification.from_pretrained('trained_bert_model')
tokenizer = BertTokenizer.from_pretrained('trained_bert_model')

def predict(filename, model, tokenizer):
    """ Prediction """
    with open(filename, 'r', encoding='utf-8') as file:
        text = file.read()

    sentences = sent_tokenize(text)
    results = []

    for idx, sentence in enumerate(sentences):
        inputs = tokenizer(sentence, return_tensors='pt', max_length=512, truncation=True, padding=True)
        outputs = model(**inputs)
        likelihood = torch.nn.functional.softmax(outputs.logits, dim=1)[0][1].item() # Probability of being AI-generated
        ai_detection = "Y" if likelihood > 0.5 else "N"
        results.append([idx + 1, sentence, f"{likelihood:.2%}", ai_detection])

    # Create and save DataFrame
    df = pd.DataFrame(results, columns=["TID", "Sentence", "AI Likelihood", "AI Detection"])
    report_file = filename.rsplit('.', 1)[0] + "_report.csv"
    df.to_csv(report_file, index=False)
    print(f"Report saved to {report_file}")

    # Calculate overall likelihood
    overall_likelihood = sum([float(row[2].strip('%'))/100 for row in results]) / len(results)
    return overall_likelihood

# Prompt user for test file name
file_name = input("Enter the name of the text file for prediction: ")
overall_likelihood = predict(file_name, model, tokenizer)

# Print summary message
summary_message = "Ohh no! The file is likely to be generated by AI." if overall_likelihood > 0.5 else "Congrats! The file is likely to be written by a human."
print(f"{summary_message} AI likelihood of {overall_likelihood:.2%}.")
